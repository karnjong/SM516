{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "[Neural networks](https://en.wikipedia.org/wiki/Artificial_neural_network) are models inspired by biological brains for learning arbitrary functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Approximation\n",
    "\n",
    "To start with, let's train a neural network to learn a simple mathematical function such as `z = sin(x) + 2*y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of samples\n",
    "n = 100\n",
    "\n",
    "# Choose n random numbers for x and y\n",
    "x = np.random.rand(n)\n",
    "y = np.random.rand(n)\n",
    "\n",
    "# Create an array of [x,y] scaled:\n",
    "# We scale the data because neural networks perform better when all inputs are\n",
    "# in a similar value range\n",
    "data = preprocessing.scale(np.stack([x,y], axis=1))\n",
    "\n",
    "# Create z.  We reshape it to an array of 1-element arrays for pyBrain\n",
    "target = (np.sin(x) + 2*y).reshape(n,1)\n",
    "\n",
    "# Create train/test split\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=.25, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.structure import TanhLayer\n",
    "\n",
    "network = buildNetwork(2, 5, 1, hiddenclass=TanhLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above creates a network with 2 inputs (x and y) has 5 hidden units and 1 output (z).\n",
    "\n",
    "Now we need to create datasets that PyBrain can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pybrain.datasets.classification import SupervisedDataSet\n",
    "\n",
    "# Create a dataset with 2 inputs and 1 output\n",
    "ds_train = SupervisedDataSet(2,1)\n",
    "\n",
    "# add our data to the dataset\n",
    "ds_train.setField('input', data_train)\n",
    "ds_train.setField('target', target_train)\n",
    "\n",
    "# Do the same for the test set\n",
    "ds_test = SupervisedDataSet(2,1)\n",
    "ds_test.setField('input', data_test)\n",
    "ds_test.setField('target', target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train our network and report it's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.0470309778331\n",
      "Test MSE: 0.0422927304237\n",
      "Train MSE: 0.0351590448988\n",
      "Test MSE: 0.0332700600733\n",
      "Train MSE: 0.0284098213327\n",
      "Test MSE: 0.0269475295626\n",
      "Train MSE: 0.0240637906702\n",
      "Test MSE: 0.0232706850741\n",
      "Train MSE: 0.0205769872461\n",
      "Test MSE: 0.0195560102946\n",
      "Train MSE: 0.0179362664597\n",
      "Test MSE: 0.0165537385038\n",
      "Train MSE: 0.0151774137556\n",
      "Test MSE: 0.0141666898109\n",
      "Train MSE: 0.01297723041\n",
      "Test MSE: 0.0116915662529\n",
      "Train MSE: 0.0110174655498\n",
      "Test MSE: 0.00985542496039\n",
      "Train MSE: 0.00939671433821\n",
      "Test MSE: 0.0082933702735\n"
     ]
    }
   ],
   "source": [
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.tools.validation import Validator\n",
    "\n",
    "# Create a trainer for the network and training dataset\n",
    "trainer = BackpropTrainer(network, ds_train)\n",
    "\n",
    "# Train for a number of epochs and report accuracy:\n",
    "for i in range(10):\n",
    "    # Train 10 epochs\n",
    "    trainer.trainEpochs(10)\n",
    "    \n",
    "    # Report mean squared error for training and testing sets\n",
    "    # `network.activateOnDataset` will return the predicted values for each input in the dataset passed to it.\n",
    "    # Then `Validator.MSE` returns the mean squared error of the returned value with the actual value.\n",
    "    print(\"Train MSE:\", Validator.MSE(network.activateOnDataset(ds_train), target_train))\n",
    "    print(\"Test MSE:\", Validator.MSE(network.activateOnDataset(ds_test), target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Neural Networks\n",
    "\n",
    "Neural networks can also be used for classification.\n",
    "\n",
    "# Digits Sample Data\n",
    "\n",
    "We'll be using the same dataset we used for the [classification notebook](classification.ipynb) - a dataset of 8x8 pixel handwritten digits such as the following:\n",
    "\n",
    "![digits](../scikitlearn/digits.png)\n",
    "\n",
    "The data is in the form of a 64 element array of integers representing grayscale values for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load all the samples for all digits 0-9\n",
    "digits = load_digits()\n",
    "\n",
    "# Assign the matrices to a variable `data`\n",
    "data = digits.data\n",
    "\n",
    "# Assign the labels to a variable `target`\n",
    "target = digits.target.reshape((len(digits.target), 1))\n",
    "\n",
    "# Split the data into 75% train, 25% test\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=.25, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build our network again.  This time we have 64 inputs and 10 outputs (1 output for each digit).  We can also create multiple hidden layers.  For example two layers of eight hidden units each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pybrain.structure import SoftmaxLayer\n",
    "\n",
    "# Create a network with 64 inputs, 2 layers of 16 hidden units and 10 outputs (for each digit 0-9)\n",
    "network = buildNetwork(data.shape[1], 16, 16, 10, hiddenclass=SoftmaxLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we'll use a dataset specifically for classification.  And we will create dummy variables for each of the labels instead of using the numerical value directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pybrain.datasets.classification import ClassificationDataSet\n",
    "\n",
    "# Create a dataset with 64 inputs\n",
    "ds_train = ClassificationDataSet(data_train.shape[1])\n",
    "\n",
    "# Set the input data\n",
    "ds_train.setField('input', data_train)\n",
    "ds_train.setField('target', target_train)\n",
    "\n",
    "# The convert to dummy variables\n",
    "# For instance, this will represent 0 as (1,0,0,0,0,0,0,0,0,0)\n",
    "# 1 as (0,1,0,0,0,0,0,0,0,0), 4 as (0,0,0,0,1,0,0,0,0,0) and so on.\n",
    "ds_train._convertToOneOfMany()\n",
    "\n",
    "# Do the same for the test set\n",
    "ds_test = ClassificationDataSet(data_test.shape[1])\n",
    "ds_test.setField('input', data_test)\n",
    "ds_test.setField('target', target_test)\n",
    "ds_test._convertToOneOfMany()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train as we did before.  We'll need to train this network for longer because the model is more complicated as is the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.749072011878\n",
      "Testing Accuracy: 0.726666666667\n",
      "Training Accuracy: 0.823311061618\n",
      "Testing Accuracy: 0.771111111111\n",
      "Training Accuracy: 0.856718634001\n",
      "Testing Accuracy: 0.826666666667\n",
      "Training Accuracy: 0.852264291017\n",
      "Testing Accuracy: 0.831111111111\n",
      "Training Accuracy: 0.842613214551\n",
      "Testing Accuracy: 0.84\n",
      "Training Accuracy: 0.853749072012\n",
      "Testing Accuracy: 0.844444444444\n",
      "Training Accuracy: 0.843355605048\n",
      "Testing Accuracy: 0.851111111111\n",
      "Training Accuracy: 0.839643652561\n",
      "Testing Accuracy: 0.835555555556\n",
      "Training Accuracy: 0.847067557535\n",
      "Testing Accuracy: 0.833333333333\n",
      "Training Accuracy: 0.855233853007\n",
      "Testing Accuracy: 0.822222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "trainer = BackpropTrainer(network, ds_train)\n",
    "\n",
    "for i in range(10):\n",
    "    trainer.trainEpochs(50)\n",
    "    \n",
    "    # We use `argmax(1)` to convert the results back from the 10 outputs to a single label\n",
    "    print(\"Training Accuracy:\", accuracy_score(target_train, network.activateOnDataset(ds_train).argmax(1)))\n",
    "    print(\"Testing Accuracy:\", accuracy_score(target_test, network.activateOnDataset(ds_test).argmax(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Reading\n",
    "\n",
    "* [PyBrain Official Documentation](http://pybrain.org/docs/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
