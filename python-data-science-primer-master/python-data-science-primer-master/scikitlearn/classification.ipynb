{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits Sample Data\n",
    "\n",
    "For these examples we'll use scikit-learn's built-in digits data.  This is a dataset of 8x8 pixel handwritten digits such as the following:\n",
    "\n",
    "![digits](digits.png)\n",
    "\n",
    "The data is in the form of a 64 element array of integers representing grayscale values for each pixel.  Each matrix also has a label with the true value of the number drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load all the samples for all digits 0-9\n",
    "digits = load_digits()\n",
    "\n",
    "# Assign the matrices to a variable `data`\n",
    "data = digits.data\n",
    "\n",
    "# Assign the labels to a variable `target`\n",
    "target = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for example, the first element is a 0 and the array of pixel values is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.,   0.,   0.,  13.,\n",
       "        15.,  10.,  15.,   5.,   0.,   0.,   3.,  15.,   2.,   0.,  11.,\n",
       "         8.,   0.,   0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.,   0.,\n",
       "         5.,   8.,   0.,   0.,   9.,   8.,   0.,   0.,   4.,  11.,   0.,\n",
       "         1.,  12.,   7.,   0.,   0.,   2.,  14.,   5.,  10.,  12.,   0.,\n",
       "         0.,   0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(target[0])\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data Across Training and Testing Sets\n",
    "\n",
    "scikit-learn offers an easy way to randomly split the data into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the data into 75% train, 25% test\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=.25, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Naive Bayes Classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "[`klearn.naive_bayes.GaussianNB`](scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)\n",
    "\n",
    "The first classifier we'll look at is Gaussian Naive Bayes.  This is a simple model that doesn't take any configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create a gaussian naive bayes model with no parameters\n",
    "model = GaussianNB()\n",
    "\n",
    "# Fit the model to our training data passing the features as the first parameter and the labels as the second\n",
    "model.fit(data_train, target_train)\n",
    "\n",
    "# Use the model to predict labels for our training set\n",
    "pred_train = model.predict(data_train)\n",
    "\n",
    "# And for the test set\n",
    "pred_test = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Our Model\n",
    "\n",
    "There are a few ways we can evaluate the model.  For example:\n",
    "\n",
    "* Accuracy: Percentage of predictions that are correct\n",
    "* Precision: The percent of predicted true values that are actually true\n",
    "* Recall: Percentage of true that were predicted to be true\n",
    "\n",
    "scikit-learn offers a number of others [metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).  For these examples, I'll just stick with accuracy, but usage is generally similar across the different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.857461024499\n",
      "Testing Accuracy: 0.833333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Print the accuracy for the training set\n",
    "print(\"Training Accuracy:\", accuracy_score(target_train, pred_train))\n",
    "\n",
    "# Print the accuracy for the test set\n",
    "print(\"Testing Accuracy:\", accuracy_score(target_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gaussian naive bayes classifier gives us about 85% accuracy.  The accuracy for the test set is slightly lower, as we would expect, but not so much lower that we should be concerned about overfitting.\n",
    "\n",
    "All the supervised classification algorithms in scikit-learn follow the same pattern as above: create the model, fit it to the data, predict labels and evaluate the results.  Because we'll be doing much the same process repeatedly, let's create a function to encapsulate all of those steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(model):\n",
    "    # Fit the model to our training data passing the features as the first parameter and the labels as the second\n",
    "    model.fit(data_train, target_train)\n",
    "\n",
    "    # Use the model to predict labels for our training set\n",
    "    pred_train = model.predict(data_train)\n",
    "\n",
    "    # And for the test set\n",
    "    pred_test = model.predict(data_test)\n",
    "    \n",
    "    # Print the accuracy for the training set\n",
    "    print(\"Training Accuracy:\", accuracy_score(target_train, pred_train))\n",
    "    \n",
    "    # Print the accuracy for the test set\n",
    "    print(\"Testing Accuracy:\", accuracy_score(target_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [K-Nearest Neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "[`sklearn.neighbors.KNeighborsClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "\n",
    "K-nearest neighbors has additional parameters that can be provided when creating the model such as the number of neighbors to use or the algorithm to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.986636971047\n",
      "Testing Accuracy: 0.975555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a model using the 10 nearest neighbors and make the weights uniform\n",
    "model = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "\n",
    "# Train the model, predict labels and evaluate\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked pretty well.  But let's see how changing the model parameters affects the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# This time, make the distance between neighbors affect the weight\n",
    "model = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "\n",
    "# Train the model, predict labels and evaluate\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is _every so slightly_ better.  \n",
    "\n",
    "**Note**: any time you are tweaking the model parameters to improve the test accuracy, you also need to include a [validation](https://en.wikipedia.org/wiki/Test_set#Validation_set) set to prevent overfitting of the test set as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Support Vector Classification](https://en.wikipedia.org/wiki/Support_vector_machine)\n",
    "[`sklearn.svm.SVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "\n",
    "First, a linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.971111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create a SVC model with a linear kernel\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a polynomial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.982222222222\n"
     ]
    }
   ],
   "source": [
    "# Create a 5th degree polynomial model\n",
    "model = SVC(kernel='poly', degree=5)\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Decision Trees](https://en.wikipedia.org/wiki/Decision_tree_learning)\n",
    "[`sklearn.tree.DecisionTreeClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.851111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default parameters, there appears to be some overfitting since the training accuracy is perfect but the testing accuracy is ~83%.  We can adjust parameters such as the depth of the tree or the number of features to use to help mitigate some of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.881217520416\n",
      "Testing Accuracy: 0.724444444444\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=8, max_features=8)\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Random Forest](https://en.wikipedia.org/wiki/Random_forest)\n",
    "[`sklearn.ensemble.RandomForestClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.928888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tweak settings such as the number of estimators to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.973333333333\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=40)\n",
    "run_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Reading\n",
    "* [scikit-learn supervised learning documentation](http://scikit-learn.org/stable/supervised_learning.html)\n",
    "* [Classification Examples](http://scikit-learn.org/stable/auto_examples/#classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
